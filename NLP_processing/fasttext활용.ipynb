{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Skip gram model 로드\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec (Fasttext) 활용해보기  \n",
    "    -fasttext는 character단위로 여러 조합을 만들어 oov(out of voca)를 보안할 수 있는 특징이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts  # some example sentences\n",
    "print(common_texts[:])\n",
    "print(len(common_texts))\n",
    "model = FastText(size=4, window=3, min_count=1)  # instantiate\n",
    "model.build_vocab(sentences=common_texts)\n",
    "model.train(sentences=common_texts, total_examples=len(common_texts), epochs=1000)  # train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## online learning으로 새로운 단어 벡터 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(vocab=12, size=4, alpha=0.025)\n",
      "[ 0.04291693 -0.01690747  0.0535338  -0.01618716]\n",
      "[ 0.00881604  0.01222524 -0.01944129 -0.00407308]\n",
      "False\n",
      "True\n",
      "[ 0.00900394 -0.04236314  0.04026207 -0.01032737]\n",
      "[ 0.00900394 -0.04236314  0.04026207 -0.01032737]\n",
      "[ 0.03528167 -0.02827537  0.06117161 -0.01264922]\n",
      "[ 0.08470255 -0.18830316  0.14384793 -0.01968226]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.wv['system'])\n",
    "print(model.wv['trees'])\n",
    "print('systemss' in model.wv.vocab) # Tests if word present in vocab\n",
    "print('ssystems42342' in model) # Tests if vector present for worda\n",
    "print(model.wv['ssystemss42342'])\n",
    "print(model.wv['ssystems'])\n",
    "print(model.wv['systems'])\n",
    "print(model.wv['system']+model.wv['ystem']+model.wv['stem']+model.wv['tem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "old_vector = np.copy(model.wv['computation'])\n",
    "print('computation' in model.wv.vocab)\n",
    "new_sentences = [\n",
    "  ['computer', 'aided', 'design'],\n",
    "     ['computer', 'science'],\n",
    "     ['computational', 'complexity'],\n",
    "    ['military', 'supercomputer'],\n",
    "    ['central', 'processing', 'unit'],\n",
    "    ['onboard', 'car', 'computer'],\n",
    " ]\n",
    "model.build_vocab(new_sentences, update=True)  # Update the vocabulary\n",
    "model.train(new_sentences, total_examples=len(new_sentences), epochs=model.epochs)\n",
    "new_vector = model.wv['computation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14463495 -0.08178335  0.01251985 -0.03327958]\n",
      "[-0.14578187 -0.08251493  0.01255858 -0.03342261]\n"
     ]
    }
   ],
   "source": [
    "print(old_vector)\n",
    "print(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print('computational' in model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04378184  0.00647251  0.03973336 -0.01973882]\n",
      "[ 0.01472269  0.02652524  0.03062194 -0.02947172]\n"
     ]
    }
   ],
   "source": [
    "print(old_vector)\n",
    "print(new_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
